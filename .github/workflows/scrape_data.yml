# .github/workflows/scrape_data.yml

name: Scrape OSM Data Daily

on:
  workflow_dispatch:
  schedule:
    # Horarios en UTC para que se ejecuten en los momentos deseados de São Paulo (UTC-3)
    
    # Ejecutar a las 08:00 UTC (05:00 São Paulo)
    - cron: '0 8 * * *'
    
    # Ejecutar a las 13:00 UTC (10:00 São Paulo)
    - cron: '0 13 * * *'
    
    # Ejecutar a las 18:00 UTC (15:00 São Paulo)
    - cron: '0 18 * * *'
    
    # Ejecutar a las 21:30 UTC (18:30 São Paulo)
    - cron: '30 21 * * *'
    
    # Ejecutar a las 00:00 UTC (21:00 São Paulo del día anterior)
    - cron: '0 0 * * *'

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest # Usará una máquina virtual de Linux
    steps:
      # 1. Clona tu repositorio para tener acceso al código
      - name: Checkout repository
        uses: actions/checkout@v4

      # 2. Configura el entorno de Python
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      # 3. Instala las dependencias de Python
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # 4. Instala las dependencias del navegador para Playwright
      - name: Install Playwright browsers
        run: playwright install --with-deps chromium

      # 5. Ejecuta el script de scraping
      - name: Run scraping script
        run: python run_update.py
        # Pasa los secretos de GitHub a las variables de entorno del script

      - name: Send Discord Notification on Success
        if: success()
        uses: tsickert/discord-webhook@v5.3.0
                with:
                  webhook: ${{ secrets.DISCORD_WEBHOOK_URL }}
                  content: "✅ **Scraper Diario de OSM completado con éxito!**"
                  username: "OSM Bot"
                  embeds: |
                    [
                      {
                        "title": "Ver Ejecución en GitHub",
                        "url": "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}",
                        "color": 65280,
                        "timestamp": "${{ toJSON(github.event.head_commit.timestamp) }}"
                      }
                    ]

      # Este paso SIEMPRE se ejecuta, pero solo si el job falló.
      - name: Send Discord Notification on Failure
        if: failure()
        uses: tsickert/discord-webhook@v5.3.0
        with:
          webhook: ${{ secrets.DISCORD_WEBHOOK_URL }}
          content: "❌ **ERROR: El Scraper Diario de OSM falló!**"
          username: "OSM Bot"
          embeds: |
            [
              {
                "title": "Ver Logs del Error en GitHub",
                "description": "El proceso de scraping no se completó. Por favor, revisa los logs para más detalles.",
                "url": "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}",
                "color": 16711680,
                "timestamp": "${{ toJSON(github.event.head_commit.timestamp) }}"
              }
            ]
        env:
          DB_HOST: ${{ secrets.DB_HOST }}
          DB_PORT: ${{ secrets.DB_PORT }}
          DB_NAME: ${{ secrets.DB_NAME }}
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          MI_USUARIO: ${{ secrets.MI_USUARIO }}
          MI_CONTRASENA: ${{ secrets.MI_CONTRASENA }}